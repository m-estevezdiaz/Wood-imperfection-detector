{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detector de inperfeccións en madeira\n",
    "### Iria Vázquez Álvarez e Miguel Estévez Díaz \n",
    "3º Robotica, Visión artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduccion:\n",
    "\n",
    "La detección de imperfecciones en la madera es un problema crucial en la industria maderera, ya que permite identificar defectos que afectan la calidad del producto final.\n",
    "Este trabajo se centra en el análisis del desempeño de diferentes técnicas de detección, utilizando descriptores HOG (Histogram of Oriented Gradients) en combinación con dos clasificadores diseñados específicamente para esta tarea: un detector HOG multiescala basado en un clasificador SVM y un clasificador MLP (Perceptrón Multicapa), y un tercer clasificador que trabaja directamente sobre las imágenes, un clasificador Cascade. Todos estos clasificadores han sido implementados y ajustados manualmente como parte del desarrollo de este proyecto.\n",
    "\n",
    "El trabajo incluye la extracción de características HOG a partir de imágenes de madera, el entrenamiento de cada uno de los clasificadores y la evaluación de su rendimiento sobre varios conjuntos de pruebas. Finalmente, estas técnicas se aplican para la detección de imperfecciones en secuencias de vídeo, lo que representa un desafío adicional debido a factores como las variaciones de iluminación, movimiento de la cámara y complejidad del fondo.\n",
    "\n",
    "El objetivo principal es comparar la efectividad de los clasificadores mencionados en términos de precisión, recall, F1-Score y capacidad de generalización en el contexto de detección en tiempo real. Este enfoque permite identificar las fortalezas y limitaciones de cada técnica, proporcionando una base sólida para futuras mejoras e implementaciones en aplicaciones prácticas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apertura das imaxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imaxes = []\n",
    "clases = []\n",
    "ben_cargadas = True\n",
    "\n",
    "for i in range(1, 1252):\n",
    "    ruta_pos = \"Base_datos/Imaxes/Positivos/Img_\" + str(i) + \".png\"\n",
    "    ruta_neg = \"Base_datos/Imaxes/Negativos/Img_\" + str(i) + \".png\"\n",
    "\n",
    "    # Procesar imagen positiva\n",
    "    img = cv2.imread(ruta_pos, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(f\"No se pudo cargar la imagen {ruta_pos}\")\n",
    "        ben_cargadas = False\n",
    "        continue\n",
    "    \n",
    "    imaxes.append(img)\n",
    "    clases.append(1)\n",
    "    \n",
    "    # Procesar imagen negativa\n",
    "    img = cv2.imread(ruta_neg, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(f\"No se pudo cargar la imagen {ruta_neg}\")\n",
    "        ben_cargadas = False\n",
    "        continue\n",
    "    \n",
    "    imaxes.append(img)\n",
    "    clases.append(0)\n",
    "         \n",
    "if ben_cargadas:\n",
    "    print(\"Imaxes cargadas correctaente\")\n",
    "else:\n",
    "    print(\"Algunha imaxe cargouse erroneamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A carga das imaxes realizase dende dúas carpetas diferentes, positivos e negativos, de maneira intercalada na mesma lista, para posteriormente dividilas en datos de adestramento e test\n",
    "\n",
    "## 2.1. Division das imaxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División dos datos para adestramento e test\n",
    "cantidad_adestramento = int(0.75 * (len(clases) / 2))\n",
    "cantidad_test = 4 \n",
    "cantidad_por_test = int(((len(clases) / 2) - cantidad_adestramento) / cantidad_test)\n",
    "\n",
    "cnts = [0, 0]\n",
    "cnts_2 = [[0, 0] for _ in range(cantidad_test)]\n",
    "\n",
    "imaxes_adestramento = []\n",
    "clases_adestramento = []\n",
    "tests_xerados = 0\n",
    "imaxes_test = [[] for _ in range(cantidad_test)]\n",
    "clases_test = [[] for _ in range(cantidad_test)]\n",
    "\n",
    "for img, clase in zip(imaxes, clases): \n",
    "    if ((cnts[0] < cantidad_adestramento and clase == 0) or (cnts[1] < cantidad_adestramento and clase == 1)):\n",
    "        imaxes_adestramento.append(img)\n",
    "        clases_adestramento.append(clase)\n",
    "        cnts[clase] += 1     \n",
    "        \n",
    "        continue\n",
    "    \n",
    "    if tests_xerados < cantidad_test:\n",
    "        if (cnts_2[tests_xerados][0] < cantidad_por_test  and cnts_2[tests_xerados][1] < cantidad_por_test):\n",
    "            imaxes_test[tests_xerados].append(img)\n",
    "            clases_test[tests_xerados].append(clase)\n",
    "            cnts_2[tests_xerados][clase] += 1\n",
    "        \n",
    "            if (cnts_2[tests_xerados][0] == cantidad_por_test - 1 and cnts_2[tests_xerados][1] == cantidad_por_test - 1):\n",
    "                tests_xerados += 1\n",
    "           \n",
    "            continue\n",
    "        \n",
    "print(\"División dos datos xerada correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La división de los datos se realiza en función de los dos primeros parámetros definidos en el bloque de código anterior, definiendo el porcentage de imagenes que queremos usar para el entrenamiento y la cantidad de tests que queremos generar con los datos restantes. En nuestro caso entrenamos el clasificador con el 75% de imagenes, es decir 1878 imaxes, dividindo as 626 imaxes restantes en 4 test de 154 imaxes cada un.\n",
    "\n",
    "# 3. Definicion do descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para el descriptor HoG\n",
    "winSize = (64, 64)\n",
    "blockSize = (8, 8)\n",
    "blockStride = (4, 4)\n",
    "cellSize = (8, 8)\n",
    "nbins = 9\n",
    "derivAperture = 1\n",
    "winSigma = -1.0\n",
    "histogramNormType = 0\n",
    "L2HysThreshold = 0.2\n",
    "gammaCorrection = True\n",
    "nlevels = 64\n",
    "\n",
    "# Crear el descriptor HoG\n",
    "hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma, histogramNormType, L2HysThreshold, gammaCorrection, nlevels)\n",
    "\n",
    "# Función para xerar os descriptores de Hog de una imaxe\n",
    "def generar_descriptor(img):\n",
    "    \"\"\"Genera los descriptores HoG para un conjunto de imágenes.\"\"\"\n",
    "    if img is not None:\n",
    "        # Redimensionar la imagen al tamaño requerido por el descriptor\n",
    "        imagen_redimensionada = cv2.resize(img, winSize)\n",
    "\n",
    "        # Convertir a escala de grises si no lo está\n",
    "        if len(imagen_redimensionada.shape) == 3:\n",
    "            imagen_redimensionada = cv2.cvtColor(imagen_redimensionada, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Aplicar un filtro bilateral para reducir el ruido preservando los bordes\n",
    "        imagen_suavizada = cv2.bilateralFilter(imagen_redimensionada, d=9, sigmaColor=75, sigmaSpace=75)\n",
    "\n",
    "        # Normalización de la imagen para ajustar los valores de píxeles\n",
    "        imagen_normalizada = cv2.normalize(imagen_suavizada, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "            \n",
    "        # Calcular el descriptor HoG\n",
    "        descriptor = hog.compute(imagen_normalizada)\n",
    "        \n",
    "        return np.array(descriptor).flatten()\n",
    "    else:\n",
    "        return None \n",
    "    \n",
    "print(\"Descriptor xerado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HoG es una técnica utilizada para describir las características locales de una imagen mediante la distribución de los gradientes de intensidad, que incluyen tanto las direcciones como las magnitudes, en regiones específicas de la imagen. El objetivo principal de HoG es capturar las formas y bordes presentes, que son fundamentales para la identificación de objetos.\n",
    "\n",
    "En este caso, utilizamos HoG como descriptor para transformar las imágenes de entrada (ya sean de tablas con o sin defectos) en vectores de características. Estos vectores se utilizan luego como entradas para los clasificadores (SVM y MLP). \n",
    "\n",
    "## Proceso para calcular el descriptor HoG\n",
    "\n",
    "1. **Preprocesamiento de la imagen:**\n",
    "   - Convertir la imagen a escala de grises (si no está ya en esa escala), ya que la intensidad de los píxeles es el dato que necesitamos para calcular los gradientes.\n",
    "   - Reducir el ruido en la imagen mediante un filtro bilateral para no perder los detalles importantes.\n",
    "   - Normalizar los valores de la imagen, potenciando máximos y discriminando mínimos.\n",
    "\n",
    "2. **Cálculo de gradientes:**\n",
    "   - Calcular el gradiente de la intensidad en cada píxel de la imagen utilizando operadores Sobel. Esto genera dos componentes para cada píxel:\n",
    "      - **Magnitud del gradiente:** \\( \\sqrt{G_x^2 + G_y^2} \\)\n",
    "      - **Orientación del gradiente:** \\( \\arctan{\\left(\\frac{G_y}{G_x}\\right)} \\)\n",
    "\n",
    "\n",
    "## Parámetros del Descriptor HoG\n",
    "\n",
    "- **`winSize (64, 64):`**  \n",
    "  Define el tamaño de la ventana de detección donde se calculan los descriptores HoG. La imagen se divide en varias ventanas de este tamaño, asegurando la captura de características relevantes sin perder información clave sobre bordes y formas.\n",
    "\n",
    "- **`blockSize (8, 8):`**  \n",
    "  Establece el tamaño de los bloques, que son agrupaciones de varias celdas. Cada bloque es la unidad básica normalizada en el descriptor HoG. Bloques pequeños, como 8×8, permiten una mejor resolución para capturar detalles locales.\n",
    "\n",
    "- **`blockStride (4, 4):`**  \n",
    "  Representa el desplazamiento entre bloques consecutivos. Un desplazamiento menor que el tamaño del bloque, como en este caso, introduce solapamiento entre ellos, lo que mejora la robustez frente a variaciones en la imagen.\n",
    "\n",
    "- **`cellSize (8, 8):`**  \n",
    "  Indica el tamaño de las celdas, que son las unidades donde se calculan los histogramas de los gradientes. Celdas pequeñas, como 8×8, capturan detalles más finos, pero aumentan el costo computacional.\n",
    "\n",
    "- **`nbins (9):`**  \n",
    "  Determina el número de bins en los histogramas de las orientaciones de los gradientes. Con 9 bins, el rango de 0° a 180° se divide en 9 intervalos de 20°, permitiendo capturar con precisión las direcciones de los bordes.\n",
    "\n",
    "\n",
    "## Observaciones de los Resultados\n",
    "\n",
    "A continuación se muestran parejas de imágenes y su descriptor HoG correspondiente:\n",
    "\n",
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/1_Hog.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/2_Hog.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/3_Hog.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/4_Hog.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "En ellas se observa que el descriptor HoG de la madera presenta histogramas más o menos estables, mientras que en las regiones con imperfecciones, los histogramas muestran irregularidades que representan la forma de dichas imperfecciones.\n",
    "\n",
    "## 3.1. Creacion dos descriptores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptores adestramento\n",
    "descriptores_adestramento = []\n",
    "for img in imaxes_adestramento:\n",
    "    descriptores_adestramento.append(generar_descriptor(img))\n",
    "print(\"Descriptores de adestramento xerado correctamente\")\n",
    "\n",
    "# Descriptores test\n",
    "descriptores_test = [[] for _ in range(cantidad_test)]\n",
    "for i in range(cantidad_test):\n",
    "    for img in imaxes_test[i]:\n",
    "        descriptores_test[i].append(generar_descriptor(img))\n",
    "        \n",
    "print(\"Descriptores de test xerado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creación de los descriptores se realiza mediante la función definida en el apartado anterior, rellenando la correspondiente lista (entrenamiento o test_número) correspondiente para cada caso, manteniendo la configuración definida (números de images para cadda función y cantidades de test) inicialmente para las imagenes.\n",
    "\n",
    "# 4. Definicion adestramento test clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mineria_negativos_dificiles(clasificador, descriptores_adestramento, clases_adestramento, tipo_clasificador):\n",
    "    # Realizar prediccións sobre o conxunto de adestramento\n",
    "    if tipo_clasificador == \"svm\":\n",
    "        _, prediccions = clasificador.predict(np.array(descriptores_adestramento, dtype=np.float32))\n",
    "    elif tipo_clasificador == \"mlp\":\n",
    "        prediccions = clasificador.predict(descriptores_adestramento)\n",
    "        prediccions = np.argmax(prediccions, axis=1)\n",
    "    else:\n",
    "        print(\"Tipo de clasificador no reconocido: debe ser 'svm' o 'mlp'.\")\n",
    "    \n",
    "    # Crear datos adestramento cos falsos positivos (predicción = 1, clase = 0) e cos verdadeiros positivos\n",
    "    datos_readestramento = []\n",
    "    clases_readestramento = []\n",
    "    cnt_falsos_positivos = 0\n",
    "    for i, clase in enumerate(clases_adestramento):\n",
    "        if ((prediccions[i] == 1 and clase == 0) or clase == 1):\n",
    "            datos_readestramento.append(descriptores_adestramento[i])\n",
    "            clases_readestramento.append(clase)\n",
    "            \n",
    "            if prediccions[i] == 1 and clase == 0:\n",
    "                cnt_falsos_positivos += 1\n",
    "            \n",
    "    # Se hay falsos positivos, proceder coa minería de negativos difíciles\n",
    "    if cnt_falsos_positivos > 0:\n",
    "        # Readestrar o clasificador cos novos datos\n",
    "        if tipo_clasificador == \"svm\":\n",
    "            clasificador.train(np.array(datos_readestramento, dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array(clases_readestramento, dtype=np.int32).reshape(-1, 1))\n",
    "        elif tipo_clasificador == \"mlp\":\n",
    "            clasificador.train(np.array(datos_readestramento, dtype=np.float32), np.array(clases_readestramento, dtype=np.int32).reshape(-1, 1))\n",
    "        \n",
    "        print(\"Readestraento completado.\")\n",
    "    else:\n",
    "        print(\"Non é necesario readestrar.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La minería de negativos difíciles consiste en identificar los falsos positivos en las predicciones de los datos de entrenamiento, después de haber entrenado el clasificador, para volver a entrenarlo con estos datos, denominados \"negativos difíciles\", junto con los datos positivos del entrenamiento.\n",
    "\n",
    "El objetivo principal de esta técnica es mejorar la precisión del modelo en las predicciones finales. Al centrarse en los casos donde el clasificador está fallando, se ajusta mejor a las características críticas que diferencian los datos positivos de los negativos, haciendo que las predicciones sean más precisas.\n",
    "\n",
    "## 4.1. Suport vector machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportes = []\n",
    "correctas = []\n",
    "\n",
    "# Crear e configurar o clasificador SVM con Kerner lineal\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setC(0.1)\n",
    "\n",
    "# Adestramento do clasificador\n",
    "svm.train(np.array(descriptores_adestramento, dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array(clases_adestramento).reshape(-1, 1))\n",
    "print(\"Adestramento completado.\")\n",
    "\n",
    "# Realizar minería de negativos difíciles (Non necesaria neste caso posto que causa sobreaprencdizaxe)\n",
    "#mineria_negativos_dificiles(svm, descriptores_adestramento, clases_adestramento, \"svm\")\n",
    "\n",
    "# Realizar as prediccións\n",
    "for i in range(cantidad_test):\n",
    "    print(\"\\nMétricas Test\", i + 1)\n",
    "    \n",
    "    # Obter as prediccións\n",
    "    _, prediccions = svm.predict(np.array(descriptores_test[i], dtype=np.float32))\n",
    "\n",
    "    # Contar o número de imaxes correctamente clasificadas\n",
    "    cnt = 0\n",
    "    for j, clase in enumerate(clases_test[i]):    \n",
    "        if clase == prediccions[j]:\n",
    "            cnt += 1\n",
    "            \n",
    "    correctas.append(cnt)\n",
    "            \n",
    "    # Obtemos o reporte de clasificación     \n",
    "    reporte = classification_report(clases_test[i], prediccions)\n",
    "    reportes.append(reporte)\n",
    "\n",
    "    # Información das métricas\n",
    "    print(\"SVM predeciu correctamente \", cnt, \" de \", len(clases_test[i]))\n",
    "    print(\"Reporte de clasificación:\", )\n",
    "    print(reporte)\n",
    "    print(\"Matriz de confusión: \")\n",
    "    print(confusion_matrix(clases_test[i], prediccions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (SVM) es un clasificador supervisado que tiene como objetivo separar los datos en diferentes clases utilizando un hiperplano óptimo en un espacio de características multidimensionales. La distancia de este hiperplano a los puntos más cercanos de cada clase (conocidos como vectores de soporte), es el margen que SVM trata de maximizar. Al maximizar este margen, el modelo logra una mejor capacidad para generalizar, es decir, para clasificar correctamente nuevos datos no vistos. En el caso de que los datos no sean separables linealmente, los SVM utilizan kernels, que son funciones de transformación, para proyectar los datos a un espacio de mayor dimensión donde sí pueden separarse. El kernel define cómo se transforman los datos para proyectarlos a un espacio de características donde sea posible separarlos, en nuestro caso usamos un kernel lineal para un problema de clasificación binaria (positivos y negativos).\n",
    "\n",
    "En este clasificador también aplicamos minería de negativos difíciles, la cuál consiste en identificar los falsos positivos en las predicciones de los datos de entrenamiento, después de haber entrenado el clasificador, para volver a entrenarlo con estos datos, denominados \"negativos difíciles\", junto con los datos positivos del entrenamiento. El objetivo principal de esta técnica es mejorar la precisión del modelo en las predicciones finales. Al centrarse en los casos donde el clasificador está fallando, se ajusta mejor a las características críticas que diferencian los datos positivos de los negativos, haciendo que las predicciones sean más precisas.\n",
    "\n",
    "El parámetro C (0.01) o parámetro de penalización controla el equilibrio entre maximizar el margen y minimizar los errores de clasificación. Valores bajos de C permiten márgenes más amplios pero con más errores, mientras que valores altos reducen los errores a costa de un margen más estrecho, lo que podría llevar al sobreajuste.\n",
    "\n",
    "### Test 1:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.88          | 0.88          | 77           |\n",
    "| 1                | 0.88          | 0.88          | 77           |\n",
    "| **accuracy**     |               |               | **0.88**     |\n",
    "| **macro avg**    | 0.88          | 0.88          | 154          |\n",
    "| **weighted avg** | 0.88          | 0.88          | 154          |\n",
    "| **Matriz de confusión** | 68 | 9 | |\n",
    "|                  | 9             | 68            |              |\n",
    "| SVM predijo correctamente 136 de 154 | | | |\n",
    "\n",
    "### Test 2:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.90          | 0.95          | 77           |\n",
    "| 1                | 0.95          | 0.90          | 77           |\n",
    "| **accuracy**     |               |               | **0.92**     |\n",
    "| **macro avg**    | 0.92          | 0.92          | 154          |\n",
    "| **weighted avg** | 0.92          | 0.92          | 154          |\n",
    "| **Matriz de confusión** | 73 | 4 | |\n",
    "|                  | 8             | 69            |              |\n",
    "| SVM predijo correctamente 142 de 154 | | | |\n",
    "\n",
    "### Test 3:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.96          | 0.95          | 77           |\n",
    "| 1                | 0.95          | 0.96          | 77           |\n",
    "| **accuracy**     |               |               | **0.95**     |\n",
    "| **macro avg**    | 0.95          | 0.95          | 154          |\n",
    "| **weighted avg** | 0.95          | 0.95          | 154          |\n",
    "| **Matriz de confusión** | 73 | 4 | |\n",
    "|                  | 3             | 74            |              |\n",
    "| SVM predijo correctamente 147 de 154 | | | |\n",
    "\n",
    "### Test 4:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.94          | 0.86          | 77           |\n",
    "| 1                | 0.87          | 0.95          | 77           |\n",
    "| **accuracy**     |               |               | **0.90**     |\n",
    "| **macro avg**    | 0.91          | 0.90          | 154          |\n",
    "| **weighted avg** | 0.91          | 0.90          | 154          |\n",
    "| **Matriz de confusión** | 66 | 11 | |\n",
    "|                  | 4             | 73            |              |\n",
    "| SVM predijo correctamente 139 de 154 | | | |\n",
    "\n",
    "# Agregar o detector svm a HOG, para usar o método multiescale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtemos o vector de soporte, o sesgo e outros parámetros do clasificador SVM\n",
    "vector_soporte = svm.getSupportVectors()\n",
    "rho,_,_= svm.getDecisionFunction(0)\n",
    "\n",
    "# Creamos o detector SVM para o descritor HoG\n",
    "detector_svm = np.zeros(vector_soporte.shape[1]+1, dtype=vector_soporte.dtype)\n",
    "detector_svm[:-1] = -vector_soporte[:]\n",
    "detector_svm[-1] = rho\n",
    "\n",
    "# Inicializamos o descritor HoG co detector SVM\n",
    "hog.setSVMDetector(detector_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente conectamos el modelo SVM entrenado con el descriptor HoG para que pueda identificar defectos en las imágenes. Primero, tomamos lo que el SVM aprendió al entrenarse, es decir, qué características son importantes para diferenciar entre defectos y no defectos. Después, adaptamos esa información para que HoG pueda usarla como una especie de \"regla\" que le permita detectar esas mismas características en nuevas imágenes.\n",
    "\n",
    "## 4.2. Clasificador en cascada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar o clasificador en cascada\n",
    "cascade = cv2.CascadeClassifier('Base_datos/cascade.xml')\n",
    "\n",
    "# Realizar as prediccións\n",
    "for i in range(cantidad_test):\n",
    "    print(\"\\nMétricas Test\", i + 1)\n",
    "\n",
    "    # Obter as prediccións\n",
    "    prediccions = []\n",
    "    for img in imaxes_test[i]:\n",
    "        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        deteccions = cascade.detectMultiScale(img, scaleFactor=1.5, minNeighbors=2, minSize=(64, 64))\n",
    "\n",
    "        # Determinar a clase detectada (detección = lista de rectangulos positivos)\n",
    "        if len(deteccions) > 0:\n",
    "            prediccions.append(1)\n",
    "        else:\n",
    "            prediccions.append(0)\n",
    "    \n",
    "    # Contar o número de imaxes correctamente clasificadas\n",
    "    cnt = 0\n",
    "    for j, clase in enumerate(clases_test[i]):\n",
    "        if clase == prediccions[j]:\n",
    "            cnt += 1\n",
    "    \n",
    "    correctas.append(cnt)\n",
    "    \n",
    "    # Obtemos o reporte de clasificación     \n",
    "    reporte = classification_report(clases_test[i], prediccions)\n",
    "    reportes.append(reporte)\n",
    "\n",
    "    # Información das métricas\n",
    "    print(\"Cascade predeciu correctamente \", cnt, \" de \", len(clases_test[i]))\n",
    "    print(\"Reporte de clasificación:\", )\n",
    "    print(reporte)\n",
    "    print(\"Matriz de confusión: \")\n",
    "    print(confusion_matrix(clases_test[i], prediccions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador en cascada es una técnica que combina múltiples clasificadores simples en una secuencia, con el objetivo de realizar una detección eficiente. El clasificador en cascada busca la detección de los objetos mediante el entrenamiento de múltiples clasificadores débiles, basándose en este caso en descriptores HAAR.  Cada uno de los clasificadores se centra en la detección de un conjunto de características diferentes, los cuales se auto ajustan durante la fase de entrenamiento. El proceso de detección consiste en la clasificación de la imagen mediante todos los clasificadores, descartando esta en caso de alguno de ellos dar una respuesta negativa.\n",
    "\n",
    "Generamos nuestro modelo utilizando Cascade Trainer GUI, una herramienta que simplifica la creación de clasificadores en cascada entrenados con nuestros propios datos. Esta herramienta automatiza el proceso de entrenamiento mediante el uso de imágenes positivas (que contienen el objeto de interés, las imperfecciones de la madera) e imágenes negativas (que no lo contienen). Internamente, se emplea Haar para describir las imágenes y entrenar los clasificadores. El modelo final, contenido en el archivo cascade.xml, incorpora toda la información necesaria, incluyendo umbrales, parámetros y características seleccionadas, lo que nos permite cargarlo y utilizarlo directamente con OpenCV para detectar objetos en imágenes o videos nuevos.\n",
    "\n",
    "### Test 1:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.59          | 0.70          | 77           |\n",
    "| 1                | 0.63          | 0.51          | 77           |\n",
    "| **accuracy**     |               |               | **0.60**     |\n",
    "| **macro avg**    | 0.61          | 0.60          | 154          |\n",
    "| **weighted avg** | 0.61          | 0.60          | 154          |\n",
    "| **Matriz de confusión** | 54 | 23 | |\n",
    "|                  | 38            | 39            |              |\n",
    "| Cascade predijo correctamente 93 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 2:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.53          | 0.65          | 77           |\n",
    "| 1                | 0.55          | 0.43          | 77           |\n",
    "| **accuracy**     |               |               | **0.54**     |\n",
    "| **macro avg**    | 0.54          | 0.54          | 154          |\n",
    "| **weighted avg** | 0.54          | 0.54          | 154          |\n",
    "| **Matriz de confusión** | 50 | 27 | |\n",
    "|                  | 44            | 33            |              |\n",
    "| Cascade predijo correctamente 83 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 3:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.51          | 0.53          | 77           |\n",
    "| 1                | 0.51          | 0.48          | 77           |\n",
    "| **accuracy**     |               |               | **0.51**     |\n",
    "| **macro avg**    | 0.51          | 0.51          | 154          |\n",
    "| **weighted avg** | 0.51          | 0.51          | 154          |\n",
    "| **Matriz de confusión** | 41 | 36 | |\n",
    "|                  | 40            | 37            |              |\n",
    "| Cascade predijo correctamente 78 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 4:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.44          | 0.40          | 77           |\n",
    "| 1                | 0.45          | 0.49          | 77           |\n",
    "| **accuracy**     |               |               | **0.45**     |\n",
    "| **macro avg**    | 0.45          | 0.45          | 154          |\n",
    "| **weighted avg** | 0.45          | 0.45          | 154          |\n",
    "| **Matriz de confusión** | 31 | 46 | |\n",
    "|                  | 39            | 38            |              |\n",
    "| Cascade predijo correctamente 69 de 154 | | | |\n",
    "\n",
    "\n",
    "## 4.3. Perceptron muticapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear o escalador para normalizar os datos\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalizar os descriptores de adestramento\n",
    "descriptores_adestramento_normalizados = scaler.fit_transform(descriptores_adestramento)\n",
    "\n",
    "# Crear e configurar o clasificador MLP\n",
    "mlp = cv2.ml.ANN_MLP_create()\n",
    "mlp.setLayerSizes(np.array([descriptores_adestramento_normalizados.shape[1], 20, 2]))  # Tamaño de las capas: 4185 entradas, 64 neuronas en capa oculta, 2 clases de salida\n",
    "mlp.setActivationFunction(cv2.ml.ANN_MLP_SIGMOID_SYM)  # Función de activación sigmoide simétrica\n",
    "mlp.setTermCriteria((cv2.TERM_CRITERIA_EPS, 10000, 1e-6))  # Criterios de término\n",
    "mlp.setTrainMethod(cv2.ml.ANN_MLP_BACKPROP)  # Método de entrenamiento Backpropagation\n",
    "\n",
    "# Convertir las clases a formato one-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "clases_adestramento_one_hot = encoder.fit_transform(np.array(clases_adestramento).reshape(-1, 1))\n",
    "\n",
    "# Adestramento do clasificador MLP\n",
    "mlp.train(np.array(descriptores_adestramento_normalizados, dtype=np.float32), cv2.ml.ROW_SAMPLE, np.array(clases_adestramento_one_hot, dtype=np.float32))\n",
    "print(\"Adestramento completado.\")\n",
    "\n",
    "# Realizar as prediccións\n",
    "for i in range(cantidad_test):\n",
    "    print(\"\\nMétricas Test\", i + 1)\n",
    "    \n",
    "    # Normalizar os descriptores de test\n",
    "    descriptores_test_normalizados = scaler.transform(np.array(descriptores_test[i], dtype=np.float32))\n",
    "\n",
    "    # Obter as prediccións\n",
    "    _, prediccions = mlp.predict(descriptores_test_normalizados)\n",
    "    \n",
    "    # Convertir as probabilidades en clases predicidas (tomando a clase co maior valor)\n",
    "    prediccions = np.argmax(prediccions, axis=1)\n",
    "\n",
    "    # Contar o número de imaxes correctamente clasificadas\n",
    "    cnt = 0\n",
    "    for j, clase in enumerate(clases_test[i]):    \n",
    "        if clase == prediccions[j]:\n",
    "            cnt += 1\n",
    "    \n",
    "    correctas.append(cnt)\n",
    "    \n",
    "    # Obtemos o reporte de clasificación     \n",
    "    reporte = classification_report(clases_test[i], prediccions)\n",
    "    reportes.append(reporte)\n",
    "\n",
    "    # Información das métricas\n",
    "    print(\"MLP predeciu correctamente \", cnt, \" de \", len(clases_test[i]))\n",
    "    print(\"Reporte de clasificación:\")\n",
    "    print(reporte)\n",
    "    print(\"Matriz de confusión: \")\n",
    "    print(confusion_matrix(clases_test[i], prediccions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Perceptrón Multicapa (MLP) es una red neuronal artificial supervisada diseñada para aprender relaciones no lineales entre las entradas y las salidas mediante capas de neuronas interconectadas. Consta de tres capas principales: una capa de entrada, que recibe las características (en este caso, los descriptores HoG); capas ocultas, encargadas de realizar transformaciones no lineales para identificar patrones complejos; y una capa de salida, que genera la predicción final. Las neuronas de cada capa están conectadas a las de la siguiente mediante pesos, los cuales se ajustan durante el entrenamiento para minimizar los errores de predicción..\n",
    "Estructura de nuestra red -> en este caso nuestra red está compuesta por:\n",
    "- Una capa de entrada con tamaño 4185, debido a que este es el tamaño de los descriptores usados.\n",
    "- Una capa oculta con 20 neuronas, adecuada para aprender los patrones relevantes.\n",
    "- Una capa de salida con 2 neuronas, una para cada clase.\n",
    "\n",
    "### Test 1:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.79          | 0.77          | 77           |\n",
    "| 1                | 0.77          | 0.79          | 77           |\n",
    "| **accuracy**     |               |               | **0.78**     |\n",
    "| **macro avg**    | 0.78          | 0.78          | 154          |\n",
    "| **weighted avg** | 0.78          | 0.78          | 154          |\n",
    "| **Matriz de confusión** | 59 | 18 | |\n",
    "|                  | 16            | 61            |              |\n",
    "| MLP predijo correctamente 120 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 2:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.90          | 0.92          | 77           |\n",
    "| 1                | 0.92          | 0.90          | 77           |\n",
    "| **accuracy**     |               |               | **0.91**     |\n",
    "| **macro avg**    | 0.91          | 0.91          | 154          |\n",
    "| **weighted avg** | 0.91          | 0.91          | 154          |\n",
    "| **Matriz de confusión** | 71 | 6  | |\n",
    "|                  | 8             | 69            |              |\n",
    "| Cascade predijo correctamente 83 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 3:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.87          | 0.88          | 77           |\n",
    "| 1                | 0.88          | 0.87          | 77           |\n",
    "| **accuracy**     |               |               | **0.88**     |\n",
    "| **macro avg**    | 0.88          | 0.88          | 154          |\n",
    "| **weighted avg** | 0.88          | 0.88          | 154          |\n",
    "| **Matriz de confusión** | 68 | 9  | |\n",
    "|                  | 10            | 67            |              |\n",
    "| Cascade predijo correctamente 78 de 154 | | | |\n",
    "\n",
    "\n",
    "### Test 4:\n",
    "\n",
    "| **precision**    | **recall**    | **f1-score**  | **support**  |\n",
    "|------------------|---------------|---------------|--------------|\n",
    "| 0                | 0.88          | 0.84          | 77           |\n",
    "| 1                | 0.85          | 0.88          | 77           |\n",
    "| **accuracy**     |               |               | **0.86**     |\n",
    "| **macro avg**    | 0.86          | 0.86          | 154          |\n",
    "| **weighted avg** | 0.86          | 0.86          | 154          |\n",
    "| **Matriz de confusión** | 65 | 12 | |\n",
    "|                  | 9             | 68            |              |\n",
    "| Cascade predijo correctamente 69 de 154 | | | |\n",
    "\n",
    "\n",
    "# 5. Comparacion funcionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de los reportes\n",
    "'''Función para extraer métricas de cada reporte'''\n",
    "def procesar_reporte(reporte_texto):\n",
    "    # Buscar precisión, recall, f1-score e accuracy\n",
    "    precision = float(re.search(r\"macro avg\\s+([\\d.]+)\", reporte_texto).group(1))\n",
    "    recall = float(re.search(r\"macro avg\\s+[\\d.]+\\s+([\\d.]+)\", reporte_texto).group(1))\n",
    "    f1_score = float(re.search(r\"macro avg\\s+[\\d.]+\\s+[\\d.]+\\s+([\\d.]+)\", reporte_texto).group(1))\n",
    "    accuracy = float(re.search(r\"accuracy\\s+([\\d.]+)\", reporte_texto).group(1))\n",
    "    return {\"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1_score, \"Accuracy\": accuracy}\n",
    "\n",
    "'''Transformar a lista de reportes'''\n",
    "reportes_procesados = [procesar_reporte(r) for r in reportes]\n",
    "\n",
    "'''Preparar datos para os plots'''\n",
    "clasificadores = [\"SVM\", \"Cascade\", \"MLP\"]\n",
    "                  \n",
    "'''Crear gráficos por cada test'''\n",
    "for test_num in range(cantidad_test):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    precision = [r[\"Precision\"] for r in reportes_procesados[test_num::cantidad_test]]\n",
    "    recall = [r[\"Recall\"] for r in reportes_procesados[test_num::cantidad_test]]\n",
    "    f1_score = [r[\"F1-Score\"] for r in reportes_procesados[test_num::cantidad_test]]\n",
    "\n",
    "    x = range(len(clasificadores))\n",
    "    plt.bar(x, precision, width=0.2, label=\"Precision\", align=\"center\")\n",
    "    plt.bar([i + 0.2 for i in x], recall, width=0.2, label=\"Recall\", align=\"center\")\n",
    "    plt.bar([i + 0.4 for i in x], f1_score, width=0.2, label=\"F1-Score\", align=\"center\")\n",
    "\n",
    "    plt.xticks([i + 0.2 for i in x], clasificadores)\n",
    "    plt.title(f\"Comparación de Métricas - Test {test_num + 1}\")\n",
    "    plt.xlabel(\"Clasificadores\")\n",
    "    plt.ylabel(\"Valor\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"y\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Cantidade predita correctamente\n",
    "'''Gráfico para mostrar predicciones correctas por test y clasificador'''\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "'''Datos para el gráfico'''\n",
    "x = range(cantidad_test)\n",
    "ancho_barra = 0.2  \n",
    "\n",
    "'''Graficar las barras para cada clasificador'''\n",
    "for idx, clasificador in enumerate(clasificadores):\n",
    "    valores_correctos = correctas[idx::len(clasificadores)]\n",
    "    posiciones = [i + (idx * ancho_barra) for i in x]\n",
    "    plt.bar(posiciones, valores_correctos, width=ancho_barra, label=clasificador)\n",
    "\n",
    "'''Configuración de la gráfica'''\n",
    "plt.xticks([i + ancho_barra for i in x], [f\"Test {i+1}\" for i in x])\n",
    "plt.title(\"Predicciones Correctas por Clasificador y Test\")\n",
    "plt.xlabel(\"Test\")\n",
    "plt.ylabel(\"Cantidad de Predicciones Correctas\")\n",
    "plt.ylim(0, cantidad_por_test * 2)\n",
    "plt.legend(title=\"Clasificadores\")\n",
    "plt.grid(axis=\"y\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/5_Metricas.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "    <td><img src=\"Apoio/Imaxes/6_Metricas.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><img src=\"Apoio/Imaxes/7_Metricas.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "    <td><img src=\"Apoio/Imaxes/5_Metricas.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td colspan=\"2\">\n",
    "      <img src=\"Apoio/Imaxes/9_Comparacion_resultados.png\" alt=\"Imagen 1\" style=\"width:100%; height:auto;\"/>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "# 6. Prova sobre video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral de Supresión de Non Máximos\n",
    "conf_threshold = 0.95\n",
    "nms_threshold = 0.05\n",
    "\n",
    "# Parametros ventana deslizante multiescalr\n",
    "ventana_inicial = (64, 64)\n",
    "paso = 64\n",
    "escalas = [1.0, 1.5, 2.0]\n",
    "\n",
    "for i in range(1, 5):\n",
    "    # Ruta e carga do vídeo\n",
    "    ruta_video = f\"Base_datos/Videos/Video_{i}.mp4\"\n",
    "    cap = cv2.VideoCapture(ruta_video)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Non se puido abrir o vídeo {ruta_video}\")\n",
    "        continue\n",
    "    \n",
    "    # Crear o obxecto VideoWriter para gardar o video resultante\n",
    "    out_video = cv2.VideoWriter(f\"Apoio/Videos/Resultado_{i}.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (width * 2, height * 2))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        # Ler o fotograma actual\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Copiar os frames para a visualización e iniciar a lista para a posterior visualización\n",
    "        frame_Hog = frame.copy()\n",
    "        frame_mlp = frame.copy()\n",
    "        frame_cascade = frame.copy()\n",
    "        frame_original = frame.copy()\n",
    "        frames = []\n",
    "\n",
    "        # Procesar con HOG\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects_hog, scores = hog.detectMultiScale(gray, winStride=(32, 32), padding=(16, 16), scale=1.2, useMeanshiftGrouping=False)\n",
    "        \n",
    "        \"\"\"Aplicar NMS e debuxar rectángulos\"\"\"\n",
    "        rects, confidences = [], []\n",
    "        for (x, y, w, h), score in zip(rects_hog, scores):\n",
    "            rects.append([x, y, x + w, y + h])\n",
    "            confidences.append(float(score))\n",
    "        indices = cv2.dnn.NMSBoxes(rects, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "        if isinstance(indices, np.ndarray) and len(indices) > 0: \n",
    "            for idx in indices.flatten():\n",
    "                x1, y1, x2, y2 = rects[idx]\n",
    "                cv2.rectangle(frame_Hog, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame_Hog, 'HOG Classifier', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Procesar co clasificador en cascada\n",
    "        deteccions = cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=3, minSize=(32, 32))\n",
    "\n",
    "        '''Convertir detecciones a formato(x, y, w, h, score)'''\n",
    "        deteccions_con_scores = []\n",
    "        for (x, y, w, h) in deteccions:\n",
    "            score = 1.0  \n",
    "            deteccions_con_scores.append([x, y, x + w, y + h, score])\n",
    "\n",
    "        '''Aplicar supresión de no máximos'''\n",
    "        deteccions_con_scores = np.array(deteccions_con_scores)\n",
    "        indices = cv2.dnn.NMSBoxes(bboxes=deteccions_con_scores[:, :4].tolist(), scores=deteccions_con_scores[:, 4].tolist(), score_threshold=0.5, nms_threshold=0.4)\n",
    "\n",
    "        '''Dibujar solo las detecciones retenidas'''\n",
    "        if len(indices) > 0:\n",
    "            for m in indices.flatten():\n",
    "                x1, y1, x2, y2 = deteccions_con_scores[m :4].astype(int)\n",
    "                cv2.rectangle(frame_cascade, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.putText(frame_cascade, 'Cascade Classifier', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Procesar co MLP\n",
    "        rects_mlp = []\n",
    "        confidences_mlp = []\n",
    "        for escala in escalas:\n",
    "            frame_escalado = cv2.resize(frame, (int(frame.shape[1] * escala), int(frame.shape[0] * escala)))\n",
    "            for y in range(0, frame_escalado.shape[0] - ventana_inicial[1], paso):\n",
    "                for x in range(0, frame_escalado.shape[1] - ventana_inicial[0], paso):\n",
    "                    roi = frame_escalado[y:y + ventana_inicial[1], x:x + ventana_inicial[0]]\n",
    "                    descriptor = generar_descriptor(roi)\n",
    "                    if descriptor is not None:\n",
    "                        des_normalizados = scaler.transform(np.array(descriptor, dtype=np.float32).reshape(1, -1))\n",
    "                        _, prediccion = mlp.predict(np.array(des_normalizados, dtype=np.float32))\n",
    "                        probabilidade_clase = np.max(prediccion, axis=1)\n",
    "                        if 0 in np.argmax(prediccion, axis=1):  # Se predice a clase obxecto\n",
    "                            x1 = int(x / escala)\n",
    "                            y1 = int(y / escala)\n",
    "                            x2 = int((x + ventana_inicial[0]) / escala)\n",
    "                            y2 = int((y + ventana_inicial[1]) / escala)\n",
    "                            rects_mlp.append([x1, y1, x2, y2])\n",
    "                            confidences_mlp.append(float(probabilidade_clase[0]))\n",
    "        \n",
    "        \"\"\"Aplicar NMS para o MLP\"\"\"\n",
    "        indices_mlp = cv2.dnn.NMSBoxes(rects_mlp, confidences_mlp, conf_threshold, nms_threshold)\n",
    "\n",
    "        if isinstance(indices_mlp, np.ndarray) and len(indices_mlp) > 0:  # Verifica se hai deteccións válidas\n",
    "            for idx in indices_mlp.flatten():\n",
    "                x1, y1, x2, y2 = rects_mlp[idx]\n",
    "                cv2.rectangle(frame_mlp, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame_mlp, 'MLP Classifier', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Escribir \"original\" no frame orixinal\n",
    "        cv2.putText(frame_original, 'Original', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Engadir frames procesados ao mosaico\n",
    "        frames.append([frame_original, frame_Hog, frame_cascade, frame_mlp])\n",
    "\n",
    "        filas = 2\n",
    "        columnas = 2\n",
    "        altura, ancho = frames[0][0].shape[:2]\n",
    "        mosaico = np.zeros((filas * altura, columnas * ancho, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Añadir os frames no mosaico\n",
    "        for j, frame_set in enumerate(frames):\n",
    "            for j, frame in enumerate(frame_set):\n",
    "                fila = j // columnas\n",
    "                columna = j % columnas\n",
    "                mosaico[fila * altura:(fila + 1) * altura, columna * ancho:(columna + 1) * ancho, :] = frame\n",
    "        \n",
    "        # Frame procesado + deteccións dos clasificadores\n",
    "        out_video.write(mosaico)\n",
    "                \n",
    "    cap.release()\n",
    "    out_video.release()\n",
    "    \n",
    "    print(\"Video\", i, \"generado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !EJECUTE LA SIGUIENTE CELDA PARA QUE SE REPRODUZCAN LOS VIDEOS RESULTANTES¡\n",
    "## Celda de reproducción de los videos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para o vídeo combinado\n",
    "fps_saida = 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# Dimensións da xanela de visualización\n",
    "ancho_visualizacion = 640\n",
    "alto_visualizacion = 360\n",
    "\n",
    "# Función para crear un frame gris con texto\n",
    "def crear_frame_transicion(ancho, alto, texto):\n",
    "    frame = np.full((alto, ancho, 3), (50, 50, 50), dtype=np.uint8)\n",
    "    cv2.putText(frame, texto, (int(ancho * 0.25), int(alto * 0.5)), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3, cv2.LINE_AA)  # Texto branco\n",
    "    return frame\n",
    "\n",
    "# Bucle de reprodución e creación do vídeo\n",
    "for i in range(1, 5):\n",
    "    print(\"Reproduciendo video\", i)\n",
    "    \n",
    "    # Ruta e carga do vídeo\n",
    "    ruta_video = f\"Apoio/Videos/Resultado_{i}.mp4\"\n",
    "    cap = cv2.VideoCapture(ruta_video)\n",
    "    fps_video = cap.get(cv2.CAP_PROP_FPS)\n",
    "    ancho = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    alto = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Non se puido abrir o vídeo {ruta_video}\")\n",
    "        continue\n",
    "\n",
    "    # Transición: frame gris con texto\n",
    "    frame_transicion = crear_frame_transicion(ancho, alto, f\"Resultados_{i}\")\n",
    "    for _ in range(fps_saida):\n",
    "        frame_redimensionado = cv2.resize(frame_transicion, (ancho_visualizacion, alto_visualizacion))\n",
    "        cv2.imshow(\"Resultados\", frame_redimensionado)\n",
    "        if cv2.waitKey(30) in [ord('q'), ord('Q'), 27]:\n",
    "            break\n",
    "\n",
    "    # Reproducir e gardar o vídeo actual\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_redimensionado = cv2.resize(frame, (ancho_visualizacion, alto_visualizacion))\n",
    "        cv2.imshow(\"Resultados\", frame_redimensionado)\n",
    "        if cv2.waitKey(30) in [ord('q'), ord('Q'), 27]:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
